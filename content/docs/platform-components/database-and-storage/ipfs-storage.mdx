---
title: "Ipfs storage"
description: Guide to using IPFS storage solutions in SettleMint
---

import { Tabs, Tab } from "fumadocs-ui/components/tabs";
import { Callout } from "fumadocs-ui/components/callout";
import { Steps } from "fumadocs-ui/components/steps";
import { Card } from "fumadocs-ui/components/card";

**InterPlanetary File System (IPFS)** is a **decentralized and distributed file
storage system** designed to enhance the way data is stored and accessed on the
web. Unlike traditional cloud storage solutions that rely on centralized
servers, **IPFS stores content across a peer-to-peer (P2P) network**, making it
**efficient, secure, and resilient** against failures and censorship.

Within **SettleMint**, **IPFS is available as a storage option**, allowing
developers to **store, retrieve, and manage files seamlessly** for blockchain
applications. It enables **off-chain data storage**, ensuring that blockchain
networks remain efficient while still being able to reference large datasets
securely. [Learn more on IPFS here](https://docs.ipfs.tech/concepts/)

### Why use ipfs?

- **Decentralized & Fault-Tolerant** – No single point of failure.
- **Content Addressability** – Files are retrieved using unique cryptographic
  **Content Identifiers (CIDs)** rather than URLs.
- **Efficient Storage & Bandwidth Optimization** – Files are **de-duplicated and
  distributed** across nodes.
- **Ideal for Blockchain Applications** – Enables **off-chain storage** while
  linking data securely to on-chain smart contracts.
- **Scalable & Cost-Effective** – No dependency on expensive centralized storage
  solutions.

---

SettleMint offers **IPFS as a decentralized storage solution**, allowing users
to store data in a **distributed, verifiable, and tamper-proof manner**. This is
particularly useful for **storing large files, metadata, documents, NFTs, and
other digital assets** that would otherwise be expensive or inefficient to store
directly on-chain.

### Features of ipfs storage in settlemint

- **Seamless File Upload & Retrieval** – Store files and retrieve them via
  **CIDs**.
- **Blockchain Integration** – Reference IPFS-stored files within **smart
  contracts**.
- **Secure & Immutable Storage** – Files stored on IPFS remain **tamper-proof**.
- **Enhanced Performance** – Optimized file access through **IPFS gateways**.
- **Redundancy & Availability** – Files are distributed across the network for
  increased resilience.

---

## Api reference

SettleMint provides **multiple IPFS APIs** as shown in your dashboard:

| **API**             | **Endpoint**                                                           | **Purpose**                                                                 |
| ------------------- | ---------------------------------------------------------------------- | --------------------------------------------------------------------------- |
| **IPFS HTTP API**   | `https://your-ipfs-name.gke-region.settlemint.com/api/v0`              | Core IPFS node operations (add, cat, get, pin)                              |
| **Gateway**         | `https://your-ipfs-name.gke-region.settlemint.com/gateway/`            | Public access to IPFS content via HTTP                                      |
| **Cluster API**     | `https://your-ipfs-name.gke-region.settlemint.com/cluster`             | Manage content across the IPFS cluster                                      |
| **Pinning API**     | `https://your-ipfs-name.gke-region.settlemint.com/pinning`             | Control pinning operations using the standard IPFS Pinning API              |

### Common IPFS HTTP API endpoints

| **HTTP Method** | **Endpoint**                             | **Description**                                         |
| --------------- | ---------------------------------------- | ------------------------------------------------------- |
| `POST`          | `/api/v0/add`                            | Uploads a file to IPFS and returns its **CID**          |
| `POST`          | `/api/v0/cat?arg=<CID>`                  | Retrieves a file's contents from IPFS using its **CID** |
| `POST`          | `/api/v0/get?arg=<CID>`                  | Downloads a file (with directory structure)             |
| `POST`          | `/api/v0/pin/add?arg=<CID>`              | Pins a file to prevent it from being garbage collected  |
| `POST`          | `/api/v0/pin/rm?arg=<CID>`               | Unpins a file                                           |
| `POST`          | `/api/v0/pin/ls?arg=<CID>&type=all`      | Lists pinned content                                    |

For complete API reference, see the [official IPFS HTTP API documentation](https://docs.ipfs.tech/reference/http/api/).

---

## Credentials & authentication

Your SettleMint IPFS instance provides the following credentials for authentication:

| **Credential**           | **Description**                                           | **Used With**                         |
| ------------------------ | --------------------------------------------------------- | ------------------------------------- |
| **Cluster API Username** | Identifies your IPFS cluster user (e.g., `your-ipfs-id`)  | Basic Auth for API requests           |
| **Cluster API Password** | Password for authenticating API requests                   | Basic Auth for API requests           |
| **Peer ID**              | Unique identifier for your node in the IPFS network        | P2P communication                     |
| **Public Key**           | Used for cryptographic verification                        | P2P communication                     |
| **Private Key**          | For signing operations (keep secure)                       | P2P operations/advanced functionality |
| **Cluster Pinning JWT**  | JWT token for authenticating to the IPFS Pinning API       | Remote pinning services               |

These credentials can be found in your SettleMint dashboard under the IPFS storage instance details.

### Authentication examples

#### Basic authentication (for HTTP API and Cluster API)

```javascript
// Basic authentication with your Cluster API credentials
const username = "your-ipfs-id"; // Your Cluster API Username
const password = "your-password"; // Your Cluster API Password
const authString = btoa(`${username}:${password}`);

fetch("https://your-ipfs-name.gke-region.settlemint.com/api/v0/add", {
  method: "POST",
  headers: {
    "Authorization": `Basic ${authString}`
  },
  body: formData // Your file in FormData format
});
```

#### JWT authentication (for Pinning API)

```javascript
// JWT authentication with your Cluster Pinning JWT Token
const jwtToken = "your-pinning-jwt-token";

fetch("https://your-ipfs-name.gke-region.settlemint.com/pinning/pins", {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${jwtToken}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    cid: "QmExample...",
    name: "important-file.txt"
  })
});
```

## Usage examples

Here are practical examples of common IPFS operations with SettleMint:

### 1. Uploading a file

```javascript
async function uploadToIPFS(file) {
  const formData = new FormData();
  formData.append('file', file);
  
  // Get credentials from your SettleMint dashboard
  const username = "your-ipfs-id"; // Your Cluster API Username
  const password = "your-password"; // Your Cluster API Password
  const authString = btoa(`${username}:${password}`);
  
  const response = await fetch("https://your-ipfs-name.gke-region.settlemint.com/api/v0/add", {
    method: "POST",
    headers: {
      "Authorization": `Basic ${authString}`
    },
    body: formData
  });
  
  const data = await response.json();
  console.log("File uploaded with CID:", data.Hash);
  return data.Hash; // Returns the CID of the uploaded file
}

// Example usage with file input
// const file = document.getElementById('fileInput').files[0];
// uploadToIPFS(file).then(cid => console.log("Use this CID in your smart contracts:", cid));
```

### 2. Retrieving a file

```javascript
async function getFileFromIPFS(cid) {
  // Get credentials from your SettleMint dashboard
  const username = "your-ipfs-id";
  const password = "your-password";
  const authString = btoa(`${username}:${password}`);
  
  const response = await fetch(`https://your-ipfs-name.gke-region.settlemint.com/api/v0/cat?arg=${cid}`, {
    method: "POST",
    headers: {
      "Authorization": `Basic ${authString}`
    }
  });
  
  // For text files
  const content = await response.text();
  console.log("File content:", content);
  return content;
  
  // For binary files (uncomment as needed)
  // const blob = await response.blob();
  // return blob;
}
```

### 3. Pinning a file permanently

```javascript
async function pinFile(cid) {
  // Get credentials from your SettleMint dashboard
  const username = "your-ipfs-id";
  const password = "your-password";
  const authString = btoa(`${username}:${password}`);
  
  const response = await fetch(`https://your-ipfs-name.gke-region.settlemint.com/api/v0/pin/add?arg=${cid}`, {
    method: "POST",
    headers: {
      "Authorization": `Basic ${authString}`
    }
  });
  
  const data = await response.json();
  console.log("Pinned:", data.Pins);
  return data;
}
```

### 4. Using the Gateway for public access

#### Gateway Configuration and Optimization

SettleMint IPFS gateways provide flexible configuration options for optimal content delivery:

##### Basic Gateway Access
```
# Standard gateway URL format
https://your-ipfs-name.gke-region.settlemint.com/gateway/ipfs/{cid}
https://your-ipfs-name.gke-region.settlemint.com/gateway/ipns/{ipns-name}
```

##### Advanced Gateway Configuration

```javascript
// Gateway configuration class
class IPFSGatewayConfig {
  constructor(baseUrl, options = {}) {
    this.baseUrl = baseUrl;
    this.options = {
      // Cache configuration
      cacheControl: options.cacheControl || 'public, max-age=3600',
      // CORS settings
      corsOrigins: options.corsOrigins || ['*'],
      // Response timeout
      timeout: options.timeout || 30000,
      // Content type restrictions
      allowedContentTypes: options.allowedContentTypes || [],
      // Bandwidth limits
      rateLimiting: {
        enabled: options.rateLimiting?.enabled || false,
        requestsPerMinute: options.rateLimiting?.requestsPerMinute || 60,
        bandwidthMBPerHour: options.rateLimiting?.bandwidthMBPerHour || 1000
      },
      // Security headers
      securityHeaders: {
        'X-Content-Type-Options': 'nosniff',
        'X-Frame-Options': 'DENY',
        'Content-Security-Policy': "default-src 'self'",
        ...options.securityHeaders
      }
    };
  }
  
  // Generate optimized gateway URL
  getOptimizedUrl(cid, options = {}) {
    const params = new URLSearchParams();
    
    // Add optimization parameters
    if (options.filename) params.append('filename', options.filename);
    if (options.download) params.append('download', 'true');
    if (options.format) params.append('format', options.format);
    if (options.timeout) params.append('timeout', options.timeout);
    
    // CAR export options
    if (options.car) {
      params.append('format', 'car');
      if (options.carVersion) params.append('car-version', options.carVersion);
    }
    
    // Subdomain isolation for security
    if (options.useSubdomain) {
      return `https://${cid}.ipfs.${this.baseUrl}/ipfs/${cid}?${params}`;
    }
    
    return `${this.baseUrl}/gateway/ipfs/${cid}?${params}`;
  }
  
  // Configure gateway caching
  async configureCache(cid, cacheOptions) {
    const headers = {
      'Cache-Control': cacheOptions.cacheControl || 'public, max-age=31536000, immutable',
      'CDN-Cache-Control': cacheOptions.cdnCacheControl || 'max-age=31536000',
      'Surrogate-Control': cacheOptions.surrogateControl || 'max-age=31536000'
    };
    
    // Store cache configuration
    await this.storeCacheConfig(cid, headers);
    return headers;
  }
}

// Usage examples
const gateway = new IPFSGatewayConfig('your-ipfs-name.gke-region.settlemint.com');

// Get download URL
const downloadUrl = gateway.getOptimizedUrl('QmXxx...', {
  download: true,
  filename: 'document.pdf'
});

// Get image with format conversion
const imageUrl = gateway.getOptimizedUrl('QmXxx...', {
  format: 'webp',
  useSubdomain: true
});
```

##### Gateway Performance Optimization

```javascript
// Implement gateway request with retry and fallback
async function fetchFromGateway(cid, options = {}) {
  const gateways = [
    'https://your-ipfs-name.gke-region.settlemint.com/gateway',
    'https://gateway.ipfs.io',  // Public fallback
    'https://cloudflare-ipfs.com'  // Alternative fallback
  ];
  
  const fetchWithTimeout = (url, timeout = 10000) => {
    return Promise.race([
      fetch(url),
      new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Gateway timeout')), timeout)
      )
    ]);
  };
  
  // Try gateways in order with exponential backoff
  for (let i = 0; i < gateways.length; i++) {
    try {
      const url = `${gateways[i]}/ipfs/${cid}`;
      const response = await fetchWithTimeout(url, options.timeout || 10000);
      
      if (response.ok) {
        // Cache successful gateway for future requests
        localStorage.setItem('preferred-gateway', gateways[i]);
        return response;
      }
    } catch (error) {
      console.warn(`Gateway ${gateways[i]} failed:`, error);
      
      // Exponential backoff before trying next gateway
      if (i < gateways.length - 1) {
        await new Promise(resolve => setTimeout(resolve, Math.pow(2, i) * 1000));
      }
    }
  }
  
  throw new Error('All gateways failed');
}

// Preload content for better performance
function preloadContent(cids) {
  cids.forEach(cid => {
    const link = document.createElement('link');
    link.rel = 'prefetch';
    link.href = `https://your-ipfs-name.gke-region.settlemint.com/gateway/ipfs/${cid}`;
    document.head.appendChild(link);
  });
}
```

##### Gateway Access Control

```javascript
// Implement token-based gateway access
class SecureGateway {
  constructor(gatewayUrl, authToken) {
    this.gatewayUrl = gatewayUrl;
    this.authToken = authToken;
  }
  
  async getSecureUrl(cid, expiresIn = 3600) {
    // Generate time-limited access token
    const token = await this.generateAccessToken(cid, expiresIn);
    
    return `${this.gatewayUrl}/ipfs/${cid}?token=${token}`;
  }
  
  async generateAccessToken(cid, expiresIn) {
    const payload = {
      cid: cid,
      exp: Date.now() + (expiresIn * 1000),
      permissions: ['read']
    };
    
    // Sign token with your auth service
    const response = await fetch('/api/generate-ipfs-token', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.authToken}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(payload)
    });
    
    const { token } = await response.json();
    return token;
  }
}
```

This configuration enables:
- **Performance Optimization** through caching and CDN integration
- **Security** with access control and content validation
- **Reliability** with fallback gateways and retry logic
- **Flexibility** with format conversion and download options

### 5. Advanced Pinning Services Configuration

SettleMint's IPFS provides comprehensive pinning capabilities including local pinning, remote pinning services, and cluster pinning:

#### Local Pinning Management

```javascript
// Advanced local pinning with metadata
async function advancedPinFile(cid, options = {}) {
  const username = "your-ipfs-id";
  const password = "your-password";
  const authString = btoa(`${username}:${password}`);
  
  // Pin with metadata
  const pinData = {
    cid: cid,
    recursive: options.recursive ?? true,
    metadata: {
      name: options.name || "Unnamed",
      description: options.description || "",
      tags: options.tags || [],
      project: options.project || "default",
      pinned_at: new Date().toISOString()
    }
  };
  
  // Store metadata separately for enhanced management
  await storeMetadata(cid, pinData.metadata);
  
  // Execute pin operation
  const response = await fetch(`https://your-ipfs-name.gke-region.settlemint.com/api/v0/pin/add?arg=${cid}&recursive=${pinData.recursive}`, {
    method: "POST",
    headers: {
      "Authorization": `Basic ${authString}`
    }
  });
  
  return response.json();
}
```

#### Remote Pinning Service Integration

SettleMint IPFS supports the standard IPFS Pinning Service API, enabling integration with external pinning services:

```javascript
// Configure remote pinning service
async function configureRemotePinning(serviceName, endpoint, accessToken) {
  const jwtToken = "your-pinning-jwt-token";
  
  const config = {
    name: serviceName,
    endpoint: endpoint,
    accessToken: accessToken,
    // Optional: Configure redundancy across multiple regions
    regions: ["us-east", "eu-west", "asia-pacific"],
    replicationFactor: 3
  };
  
  const response = await fetch("https://your-ipfs-name.gke-region.settlemint.com/pinning/remote/service/add", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${jwtToken}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify(config)
  });
  
  return response.json();
}

// Pin to remote service with advanced options
async function remotePinWithOptions(cid, options = {}) {
  const jwtToken = "your-pinning-jwt-token";
  
  const pinRequest = {
    cid: cid,
    name: options.name || `Pin-${Date.now()}`,
    origins: options.origins || [],
    meta: {
      description: options.description,
      tags: options.tags || [],
      app: "settlemint-ipfs"
    },
    // Pin expiration (optional)
    expires: options.expires || null,
    // Pin delegates (who can manage this pin)
    delegates: options.delegates || []
  };
  
  const response = await fetch("https://your-ipfs-name.gke-region.settlemint.com/pinning/pins", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${jwtToken}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify(pinRequest)
  });
  
  const result = await response.json();
  
  // Monitor pin status
  return monitorPinStatus(result.requestid);
}

// Monitor pinning progress
async function monitorPinStatus(requestId) {
  const jwtToken = "your-pinning-jwt-token";
  
  const checkStatus = async () => {
    const response = await fetch(`https://your-ipfs-name.gke-region.settlemint.com/pinning/pins/${requestId}`, {
      headers: {
        "Authorization": `Bearer ${jwtToken}`
      }
    });
    
    const status = await response.json();
    
    if (status.status === "pinned") {
      return status;
    } else if (status.status === "failed") {
      throw new Error(`Pinning failed: ${status.error}`);
    }
    
    // Continue monitoring
    await new Promise(resolve => setTimeout(resolve, 2000));
    return checkStatus();
  };
  
  return checkStatus();
}
```

#### Cluster Pinning Configuration

For high availability and redundancy, use IPFS cluster pinning:

```javascript
// Cluster pin with replication
async function clusterPin(cid, options = {}) {
  const username = "your-ipfs-id";
  const password = "your-password";
  const authString = btoa(`${username}:${password}`);
  
  const clusterOptions = {
    replication_factor_min: options.minReplicas || 2,
    replication_factor_max: options.maxReplicas || 3,
    name: options.name || "",
    user_allocations: options.preferredNodes || [],
    expire_at: options.expiresAt || null,
    metadata: {
      application: "settlemint",
      ...options.metadata
    },
    pin_update: options.updateExisting || false
  };
  
  const response = await fetch(`https://your-ipfs-name.gke-region.settlemint.com/cluster/pins/${cid}`, {
    method: "POST",
    headers: {
      "Authorization": `Basic ${authString}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify(clusterOptions)
  });
  
  return response.json();
}

// Get cluster pin status
async function getClusterPinStatus(cid) {
  const username = "your-ipfs-id";
  const password = "your-password";
  const authString = btoa(`${username}:${password}`);
  
  const response = await fetch(`https://your-ipfs-name.gke-region.settlemint.com/cluster/pins/${cid}`, {
    headers: {
      "Authorization": `Basic ${authString}`
    }
  });
  
  const status = await response.json();
  
  // Returns detailed status including:
  // - peer_map: which peers have the content
  // - replication_factor: current replication count
  // - allocations: where content is allocated
  return status;
}
```

# Interplanetary file system (ipfs)

InterPlanetary File System (IPFS) is an open-source, peer-to-peer distributed
file system for storing and accessing content on the decentralized web. Unlike
traditional HTTP-based systems that locate data by server address (URL), IPFS
uses content addressing – identifying data by its content hash – to retrieve
files from any node that holds them. By combining ideas from well-established
technologies (like distributed hash tables and Git-like Merkle trees), IPFS
enables a global, versioned, and content-addressable storage network.

This document provides a technical overview of IPFS, explaining its underlying
architecture and practical usage for developers, architects, and technically
inclined stakeholders. We will cover IPFS's foundational principles, how files
are stored and retrieved via content IDs (CIDs), the core components and
protocols that make up IPFS, methods of interacting with the network, common
usage patterns (from file sharing to dApp integration), as well as the benefits,
limitations, and best practices for deploying IPFS in production environments.

## Foundational principles of ipfs

IPFS is built on several key principles that distinguish it from traditional
file storage and sharing systems:

### Content addressing and cids

At the heart of IPFS is content addressing – every piece of data is identified
by a content identifier (CID) which is derived from the data itself (via a
cryptographic hash). In simpler terms, the address of a file in IPFS is its
content, not the location of a server. This means that if two files have exactly
the same content, they will have the same CID, and that CID will always refer to
that content regardless of where it is stored.

When a file is added to IPFS, it's split into fixed-size blocks (chunks) and
each block is hashed; a final hash (CID) is produced for the entire file (often
represented as a root node linking all the chunks). The CID is effectively a
unique fingerprint of the content, and even a small change in the file will
produce a completely different CID.

Content addressing provides strong integrity guarantees: if you fetch data by
its CID, you can verify (by re-hashing) that the content matches the CID you
requested. This removes the need to trust a particular server – you're trusting
the cryptographic hash. CIDs are designed with a flexible format (using
multihash and multicodec conventions) that includes metadata about the hashing
and encoding, but conceptually a CID is just a hash of content.

In summary, IPFS's content addressing decouples the what (the data) from the
where (the location), enabling data to be retrieved from any peer in the network
that has it.

### Merkle dag (content linking and immutability)

IPFS represents data as a Merkle Directed Acyclic Graph (Merkle DAG) – a
structure in which each node (file block or object) is linked via hashes to
other nodes. Every file added to IPFS is stored as a Merkle DAG: if the file is
small enough it might be a single block (node) whose CID is the hash of the
file, but larger files are broken into many hashed blocks linked together
(Lesson: Turn a File into a Tree of Hashes | IPFS Primer).

The top-level node (often called a root) contains links (hash pointers) to its
constituent blocks, which may themselves link to sub-blocks, forming a tree of
hashes. Because each link is a hash, the entire structure is
self-authenticating: the root CID effectively seals the content of the whole
file tree.

The use of Merkle DAGs means content is immutable – once data is added, that
exact data will always correspond to the same CID. If you update a file, the
modified file will produce a new CID, while the old version remains addressable
by the old hash (this enables versioning, as discussed later). Merkle DAGs also
enable deduplication: if two files share common chunks, those chunks (being
identical content) have the same CID and can be stored only once and referenced
in multiple graphs, saving space.

IPFS's data model, called IPLD (InterPlanetary Linked Data), generalizes this
Merkle DAG structure so that many data types (files, directories, Git trees,
blockchains, etc.) can be represented and linked by their hashes. On top of
IPLD, IPFS uses UnixFS as a higher-level schema for files and directories,
allowing hierarchical file systems to be built using Merkle DAG nodes (for
example, directories are nodes that list hashes of their children).

The Merkle DAG approach gives IPFS its properties of content integrity and
naturally supports a versioned file system (much like how Git commits form a DAG
of versions).

### Peer-to-peer networking and decentralization

IPFS operates over a distributed peer-to-peer (P2P) network of nodes rather than
client-server architecture. Any computer running an IPFS node can participate in
the network, storing data and fulfilling requests from others. There are no
central servers holding the authoritative copy of content; instead, content is
shared and cached by many peers.

When you request a CID on IPFS, the system doesn't query a single location – it
asks the network which peers have the content and retrieves it from whichever
peer (or peers) can serve it fastest. This P2P design makes IPFS inherently
decentralized and resilient: even if some nodes leave or go offline, data can
still be retrieved from other nodes that have it, with no single point of
failure.

Peers discover and communicate with each other using a networking library called
libp2p, which handles peer addressing, secure transport, and multiplexing for
the IPFS network. Each IPFS node has a unique Peer ID (derived from a
cryptographic key) which is used to identify it in the network, and nodes
connect to each other via swarm addresses (multiaddresses) over various
transport protocols (TCP, UDP, QUIC, etc.).

This peer network forms the substrate over which IPFS content is distributed. A
new node joining IPFS initially connects to a set of bootstrap peers and then
learns about other peers progressively. In essence, IPFS creates a global swarm
of peers that collectively store and serve content, akin to a sophisticated
BitTorrent-like swarm but for a unified filesystem.

## Ipfs architecture and core components

Under the hood, IPFS is composed of several interconnected subsystems that work
together to enable content-addressed storage and retrieval. The core components
of IPFS include the node software (sometimes called a Kubo node, formerly
go-ipfs), the distributed hash table for peer/content discovery, the Bitswap
exchange protocol, and the IPLD data model layer. Let's explore these components
in more detail:

### Ipfs nodes and repositories

An IPFS node is a program (and by extension, the machine running it) that
participates in the IPFS network. Each node stores data in a local repository
which contains the content blocks the node has pinned or cached, as well as
indexing information. Nodes can be run by anyone – from personal laptops to
servers – and all nodes collectively form the IPFS network.

Each node is identified by a Peer ID, and can have multiple network addresses
through which it connects to others. IPFS nodes communicate over libp2p, meaning
they use a modular networking stack that can run over various transports and
apply encryption and NAT traversal as needed. When running, a node continuously
maintains connections to a set of peers.

Nodes do not automatically replicate all data; instead, a node stores only the
content it intentionally adds or "pins", plus any other content it has fetched
(which it may cache temporarily). By default, IPFS treats stored data like a
cache – it may be garbage-collected if not pinned (more on pinning in a later
section). This design ensures that participating in IPFS doesn't mean storing
the entire network's data, only what each node finds relevant.

The node exposes a few interfaces for users/applications: a command-line
interface, a RESTful HTTP API, and optionally a gateway interface for browser
access. In essence, an IPFS node is a self-contained peer that can store content
(in a local Merkle block store), connect to other peers, advertise the content
it holds, and fetch content from others upon request.

### Distributed hash table (dht) for content routing

To locate which nodes have a given piece of content (CID), IPFS relies on a
distributed hash table (DHT) called Kademlia. The IPFS DHT is a decentralized
index that maps CIDs to the peer IDs of nodes that can provide that content.
When a node adds content to IPFS, it announces (publishes) to the DHT that "Peer
X has content with CID Y". Later, when some node wants to retrieve that CID, it
performs a DHT lookup to find provider records – essentially the network
addresses of peers who have the content.

The DHT is spread across all IPFS nodes (or specifically, those that support the
DHT – some light nodes might use delegate servers). It uses Kademlia's XOR-based
routing: each peer is responsible for a portion of the hash space and knows how
to route queries closer to the target CID's key. In practical terms, an IPFS
node searching for content will query the DHT by hashing the CID and finding the
closest peers in the key space, who either know the provider or can refer the
query further along.

The public IPFS DHT (sometimes called the Amino DHT) is a global, open network
averaging thousands of peers. It is designed to handle churn (peers
joining/leaving) gracefully and to find providers within a short time (most
lookups complete in well under 2 seconds on the public network. The DHT makes
IPFS content routing decentralized – there is no central index server, the "who
has what" information is distributed among all peers.

In addition to the DHT, IPFS can also use mDNS (multicast DNS) for discovering
peers on a local network (useful for LAN or offline scenarios), and can fall
back to delegated routing (asking a trusted server to perform DHT queries on
behalf of lightweight nodes) in constrained environments. But the primary
mechanism is the Kademlia DHT which allows any node to ask the network for
providers of a given CID.

### Bitswap: the block exchange protocol

Once you know which peers have the content you want, the next step is to
retrieve the data. IPFS uses a protocol called Bitswap to coordinate the
transfer of content blocks between peers.. When an IPFS node needs blocks
(identified by CIDs), it sends out Bitswap wantlist messages to peers it's
connected to, asking for those CIDs. Peers that have the requested blocks will
respond by sending them back.

A key feature of Bitswap is that it's not restricted to a single file "swarm" –
an IPFS node might be simultaneously exchanging blocks for many different files
with many peers. Bitswap also allows parallel downloads: if multiple peers have
a block, a node can fetch different blocks from different peers, increasing
throughput for large files. Essentially, Bitswap enables a node to assemble
content by grabbing pieces from any peers that can provide them, which can
dramatically speed up retrieval for popular content (swarming).

Peers running Bitswap maintain a ledger to incentivize fairness (they track data
exchanged and generally prefer to send to peers who reciprocate, to avoid
freeloaders). Interestingly, Bitswap can also discover content in the process of
transfer – if you connect to some peers and request a block, even if they don't
have it, they might forward the request or later receive the block and then send
it, functioning as a dynamic supply network. This means Bitswap acts as both a
data transfer protocol and a limited content discovery mechanism (for example, a
node might learn about a provider when that provider responds to a third party's
request in a swarm).

Overall, Bitswap is the engine that moves blocks around in IPFS: it's how data
actually gets from point A to point B (or C, D, etc.), once point B knows that
point A (and others) have what it needs.

### Ipld and data formats

IPLD (InterPlanetary Linked Data) is the data model layer of IPFS that defines
how structured data is represented as content-addressable objects. All content
in IPFS – files, directories, and other complex data – is expressed in terms of
IPLD nodes and links. An IPLD node can be thought of as a small data object
(e.g., a file chunk or a directory listing) with a content-addressable
identifier (CID). Links between IPLD nodes are just CIDs pointing to other
nodes, which, thanks to content addressing, also serve as cryptographic
pointers. The Merkle DAG we discussed earlier is essentially an IPLD instance.

IPLD is designed to be flexible: it supports multiple codecs and formats
(through the multicodec mechanism) so that it can interoperate with data from
other systems. For example, Git commits and Ethereum blocks can both be
represented as IPLD nodes – IPFS doesn't just handle "files" but any data that
can be content-addressed. In the context of typical file storage, the main IPLD
format is UnixFS, which defines how file data and metadata (like filenames,
sizes, directory structure) are represented in the DAG. When you add a file via
ipfs add, it is chunked and encoded into an IPLD UnixFS DAG automatically.

IPLD gives IPFS advantages like easy upgradability and interoperability: new
data structures or hash functions can be introduced without breaking the system,
because CIDs are self-describing and IPLD provides a common framework. IPLD is
the component that ensures IPFS isn't limited to a single file format or data
type – it's a universal graph layer where any content-addressed data structure
can be modeled and linked.

## Storing and retrieving files on ipfs

One of the core functions of IPFS is, of course, adding files and getting them
back. Let's walk through how files are stored and retrieved in IPFS using
content addressing and the components above:

### Adding (storing) a file

Suppose you want to store a file on IPFS. Using the IPFS CLI or API, you run
`ipfs add <filename>`. The IPFS node first chunkifies the file into blocks
(default ~256 KB each) and generates cryptographic hashes for each block. If the
file is small enough to fit in one block, that block's hash is the file's CID.
If the file is larger, IPFS creates a Merkle DAG: it will create a root IPFS
object (a kind of meta-block) that contains the hashes (CIDs) of all the file's
chunks as links. This root object gets its own hash which becomes the CID
representing the entire file.

IPFS then stores all these blocks in the local repository. As a final step, the
node announces to the network that it has this content. It does so by publishing
a provider record in the DHT for the file's root CID (and possibly for each
block CID) – essentially telling the DHT, "Peer X can provide CID Y". Once
added, the content is now available to any other IPFS peer that requests it by
that CID.

Notably, adding a file to IPFS does not mean the whole world immediately gets a
copy – it means the file is now available on the network through your node.
Other peers can retrieve it if they know the CID or discover it. Also, IPFS
ensures identical content isn't duplicated: if you add a file that contains some
blocks already present on your node (or if you add the exact same file twice),
it will reuse the existing blocks rather than store duplicates, thanks to
content-addressing (this deduplication can work across files and even across
users in the network in cases where the same chunks are shared).

### Retrieving a file

Now, how does someone fetch that file using IPFS? Given the CID of the content,
an IPFS node will perform a lookup to find who has the data, then fetch the data
block by block. In practice, the process works in two phases: content routing
and content transfer.

First, the node uses the DHT (or other discovery methods) to ask, "Who has CID
X?" It sends queries through the DHT network until it finds one or more provider
records for that CID (e.g., it learns that Peer X at such-and-such address can
serve it). With provider info in hand, the node opens connections (via libp2p)
to one or more of those peers.

Next comes the Bitswap phase: the node sends a wantlist for the CID (if it's a
multi-block file, it will request the root block first, then proceed to request
the linked blocks). The peer(s) holding the data respond by sending the blocks
over. If multiple peers have the content, the downloading node can get different
chunks from different peers in parallel, potentially speeding up the transfer.
As blocks arrive, IPFS verifies each block's hash against the expected CID,
ensuring data integrity.

When all the pieces are retrieved, IPFS assembles them (following the DAG links)
to reconstruct the original file. The user who requested the file can now read
the content (e.g., the `ipfs cat <CID>` command will output the file's data once
fetched). Importantly, the act of retrieving also caches the data on the
downloader's node: now that node can serve the file to others as well, at least
temporarily.

By design, IPFS retrieval is location-agnostic – it doesn't matter where the
content comes from, as long as the content hash matches. You could get one chunk
from a server across the ocean and another from a peer on your local network;
the resulting file is verified and identical to the original. This distributed
retrieval provides robustness and potentially better performance through
locality (if a nearby node has the data) and redundancy. And since content is
addressed by hash, IPFS ensures you never get the wrong file – if someone tries
to send bogus data, the hash won't match and it will be rejected.

## Data persistence and pinning

By design, IPFS is agnostic about persistence: it doesn't automatically make
content permanent or highly available; it simply provides the mechanism to
distribute and retrieve it. Persistence in IPFS is the responsibility of nodes
that care about the data. When you add a file to IPFS, your local node now has a
copy and will serve it to others – as long as you keep that node running and
don't remove the data. Other nodes that download that file may cache it, but
caches are not guaranteed to stay forever (nodes have limited storage and will
eventually clean up data that isn't explicitly marked to keep).

The act of marking data as "do not delete" on an IPFS node is called pinning.
Pinning a CID on a node tells that node to store the data indefinitely, exempt
from garbage collection. For example, after adding content, you'd typically pin
it on at least one node (often the same node that added it is automatically
pinning it by default). If content is not pinned, an IPFS node treats it as
cache – it might be dropped if space is needed or if the node operator runs
`ipfs repo gc` (garbage collect). Therefore, to achieve persistence, someone
must pin the data on a persistent IPFS node.

In a decentralized context, this could be the original uploader or any number of
volunteers or service providers who decide the content is worth keeping. IPFS
itself doesn't replicate content across the network without instruction; you
either rely on others to fetch and thereby temporarily host it, or you use
additional services to distribute copies. Many decentralized storage setups use
multiple IPFS nodes (or pinning services) to ensure there are always several
online copies of important data. If no node pins a piece of content and no

## SDK Usage: @settlemint/sdk-ipfs

The SettleMint IPFS SDK provides a high-level, TypeScript-first interface for interacting with IPFS:

### Installation

```bash
npm install @settlemint/sdk-ipfs
# or
yarn add @settlemint/sdk-ipfs
```

### SDK Initialization

```typescript
import { SettleMintIPFS, IPFSConfig } from '@settlemint/sdk-ipfs';

// Initialize with your SettleMint credentials
const config: IPFSConfig = {
  endpoint: 'https://your-ipfs-name.gke-region.settlemint.com',
  auth: {
    username: 'your-ipfs-id',
    password: 'your-password'
  },
  // Optional advanced configuration
  options: {
    timeout: 30000,
    retries: 3,
    gateway: {
      preferLocal: true,
      fallbackPublic: true
    }
  }
};

const ipfs = new SettleMintIPFS(config);
```

### File Operations with SDK

```typescript
// Upload file with advanced options
const uploadResult = await ipfs.add(file, {
  pin: true,
  wrapWithDirectory: true,
  progress: (bytes) => console.log(`Uploaded: ${bytes}`),
  metadata: {
    name: 'Important Document',
    tags: ['legal', 'contract'],
    project: 'smart-contract-123'
  }
});

console.log('File CID:', uploadResult.cid);
console.log('Directory CID:', uploadResult.directoryCid);

// Batch upload
const files = [
  { path: 'folder/file1.txt', content: 'Content 1' },
  { path: 'folder/file2.txt', content: 'Content 2' }
];

const batchResult = await ipfs.addAll(files, {
  wrapWithDirectory: true,
  onFileAdded: (file) => console.log(`Added: ${file.path}`)
});

// Retrieve with caching
const content = await ipfs.cat(cid, {
  cache: true,
  cacheTTL: 3600  // 1 hour
});

// Stream large files
const stream = await ipfs.catStream(cid);
stream.pipe(fs.createWriteStream('output.file'));
```

### Pin Management with SDK

```typescript
// Pin with metadata and tracking
const pinResult = await ipfs.pin.add(cid, {
  recursive: true,
  metadata: {
    name: 'Critical Data',
    description: 'Smart contract state backup',
    tags: ['backup', 'critical'],
    expiresAt: new Date('2025-12-31')
  }
});

// Advanced pin queries
const pins = await ipfs.pin.ls({
  type: 'recursive',
  filter: {
    tags: ['critical'],
    beforeDate: new Date(),
    minSize: 1000000  // 1MB+
  },
  sort: 'size_desc',
  limit: 100
});

// Pin health monitoring
const health = await ipfs.pin.verify(cid);
console.log('Pin health:', health.status);  // 'healthy', 'corrupted', 'partial'

// Remote pinning with monitoring
const remotePinJob = await ipfs.pin.remote.add(cid, {
  service: 'pinata',
  name: 'Cross-region backup',
  regions: ['us-east', 'eu-west'],
  onProgress: (progress) => {
    console.log(`Pinning progress: ${progress.percentage}%`);
  }
});

// Wait for completion
await remotePinJob.waitForCompletion();
```

### IPNS Publishing with SDK

```typescript
// Publish to IPNS with key management
const key = await ipfs.key.gen('my-app-key', {
  type: 'rsa',
  size: 2048
});

const published = await ipfs.name.publish(cid, {
  key: 'my-app-key',
  lifetime: '24h',
  ttl: '10m',
  resolve: false
});

console.log('IPNS Name:', published.name);
console.log('Access at:', `https://your-gateway/ipns/${published.name}`);

// Update IPNS record
const updated = await ipfs.name.publish(newCid, {
  key: 'my-app-key',
  lifetime: '24h'
});
```

### Smart Contract Integration

```typescript
// Helper for smart contract integration
class IPFSContractHelper {
  constructor(private ipfs: SettleMintIPFS) {}
  
  // Upload and prepare for smart contract
  async uploadForContract(file: File, contractAddress: string) {
    // Upload with contract metadata
    const result = await this.ipfs.add(file, {
      pin: true,
      metadata: {
        contractAddress,
        uploadedAt: Date.now(),
        fileHash: await this.calculateHash(file)
      }
    });
    
    // Generate proof of existence
    const proof = await this.generateProof(result.cid, file);
    
    return {
      cid: result.cid,
      cidBytes32: this.cidToBytes32(result.cid),
      proof,
      gatewayUrl: this.ipfs.gateway.url(result.cid)
    };
  }
  
  // Convert CID to bytes32 for Solidity
  cidToBytes32(cid: string): string {
    const bytes = this.ipfs.utils.cidToBytes(cid);
    return '0x' + bytes.toString('hex').padEnd(64, '0');
  }
  
  // Verify on-chain reference
  async verifyOnChain(cid: string, contractData: string): Promise<boolean> {
    const content = await this.ipfs.cat(cid);
    const contentHash = await this.calculateHash(content);
    return contentHash === contractData;
  }
}
```

### Error Handling and Resilience

```typescript
// Implement retry logic and fallbacks
const resilientIPFS = ipfs.withResilience({
  retries: 3,
  retryDelay: 1000,
  fallbackGateways: [
    'https://ipfs.io',
    'https://cloudflare-ipfs.com'
  ],
  onError: (error, attempt) => {
    console.error(`Attempt ${attempt} failed:`, error);
  }
});

// Use with automatic retry
try {
  const content = await resilientIPFS.cat(cid);
} catch (error) {
  if (error.code === 'TIMEOUT') {
    console.error('All retries exhausted');
  }
}
```

## Use cases for ipfs in blockchain applications

### 1. **Smart contract data storage**

- Instead of storing large data **on-chain**, store it **off-chain** on IPFS and
  reference the **CID** in smart contracts.
- Example: **Legal documents, digital agreements, audit records**.

### 2. **NFT metadata & digital assets**

- Store **metadata, images, and media** for NFTs in a decentralized and
  tamper-proof manner.
- Example: **NFT artwork, game assets, token metadata**.

### 3. **Decentralized identity & credentials**

- Store and verify **identity documents, certificates, and credentials**
  securely on IPFS.
- Example: **Verifiable credentials in education, healthcare, and finance**.

### 4. **Immutable data storage for regulatory compliance**

- Ensure **auditable and tamper-proof records** for compliance-heavy industries.
- Example: **Financial records, compliance reports, supply chain tracking**.

---

## Alternative Ways to Interact with IPFS

<Tabs items={['File Manager GUI', 'JavaScript/TypeScript', 'Python', 'Go', 'Java', 'CLI']}>
  <Tab value="File Manager GUI">
    ### IPFS File Manager Interface

    SettleMint provides a comprehensive **web-based File Manager** for your IPFS storage, offering advanced file management capabilities without writing code.

    #### Advanced File Manager Features

    ##### File Operations
    - **Multi-file Upload** – Upload multiple files simultaneously with drag-and-drop or file selection
    - **Folder Upload** – Upload entire directory structures while preserving hierarchy
    - **Batch Operations** – Select multiple files for bulk pinning, unpinning, or deletion
    - **File Preview** – Preview images, videos, and text files directly in the interface
    - **Download Management** – Download individual files or export multiple files as archives

    ##### Content Management
    - **Advanced Search** – Search by CID, filename, file type, size, or upload date
    - **Filtering & Sorting** – Filter by pin status, file type, or size; sort by name, size, or date
    - **Metadata Viewer** – View detailed metadata including hash algorithm, chunk size, and DAG structure
    - **Version History** – Track different versions of files with their respective CIDs
    - **Tag Management** – Add custom tags to files for better organization

    ##### Pin Management Dashboard
    - **Pin Status Overview** – Visual indicators showing pin status across all files
    - **Pin Queue Management** – Monitor ongoing pinning operations and their progress
    - **Remote Pinning** – Configure and manage remote pinning services
    - **Pin Analytics** – View statistics on pinned content size and distribution
    - **Auto-pinning Rules** – Set rules to automatically pin files based on criteria

    ##### Integration Features
    - **Smart Contract Integration** – Generate code snippets for referencing CIDs in smart contracts
    - **IPNS Publishing** – Publish mutable references to content using IPNS
    - **Gateway Preview** – Test content accessibility through different gateway configurations
    - **API Key Management** – Generate and manage API keys for programmatic access
    - **Webhook Configuration** – Set up webhooks for file events (upload, pin, unpin)

    #### Accessing the Enhanced File Manager

    <Steps>
      <Step>Navigate to your IPFS instance in the SettleMint dashboard</Step>
      <Step>Click the **File Manager** tab</Step>
      <Step>Use the toolbar for quick actions:
        - **Import** – Add new files or folders
        - **Create Folder** – Organize files in directories
        - **Pin Manager** – Access pinning configuration
        - **Settings** – Configure file manager preferences
      </Step>
    </Steps>

    #### File Manager Best Practices

    <Callout type="info">
      **Pro Tips:**
      - Use folders to organize related files (e.g., `/nft-collections/collection-1/`)
      - Tag files with project names for easy filtering
      - Set up auto-pinning rules for critical content
      - Monitor pin queue during large uploads
      - Use batch operations to manage multiple files efficiently
    </Callout>
  </Tab>

  <Tab value="JavaScript/TypeScript">
    ### JavaScript/TypeScript Integration

    #### js-ipfs-http-client
    The official JavaScript client library for IPFS HTTP API:

    ```bash
    # Install using npm
    npm install ipfs-http-client
    # or using yarn
    yarn add ipfs-http-client
    ```

    ```javascript
    import { create } from 'ipfs-http-client'

    // Connect to your SettleMint IPFS node
    const auth = 'Basic ' + Buffer.from('your-ipfs-id:your-password').toString('base64')
    const client = create({
      host: 'your-ipfs-name.gke-region.settlemint.com',
      port: 443,
      protocol: 'https',
      apiPath: '/api/v0',
      headers: {
        authorization: auth
      }
    })

    // Upload file example
    const addFile = async (file) => {
      const added = await client.add(file)
      return added.cid.toString()
    }

    // Retrieve file example
    const getFile = async (cid) => {
      const chunks = []
      for await (const chunk of client.cat(cid)) {
        chunks.push(chunk)
      }
      return Buffer.concat(chunks)
    }
    ```
  </Tab>

  <Tab value="Python">
    ### Python Integration

    #### ipfshttpclient
    Python client library for the IPFS HTTP API:

    ```bash
    pip install ipfshttpclient
    ```

    ```python
    import ipfshttpclient
    import base64

    # Connect to your SettleMint IPFS node
    auth = base64.b64encode(b"your-ipfs-id:your-password").decode("ascii")
    client = ipfshttpclient.connect(
        '/dns/your-ipfs-name.gke-region.settlemint.com/https',
        headers={'Authorization': f'Basic {auth}'}
    )

    # Upload file example
    def add_file(file_path):
        res = client.add(file_path)
        return res['Hash']

    # Retrieve file example
    def get_file(cid):
        return client.cat(cid)
    ```
  </Tab>

  <Tab value="Go">
    ### Go Integration

    #### go-ipfs-api
    Official Go client library for the IPFS HTTP API:

    ```bash
    go get github.com/ipfs/go-ipfs-api
    ```

    ```go
    package main

    import (
        "fmt"
        "os"
        "encoding/base64"
        
        shell "github.com/ipfs/go-ipfs-api"
    )

    func main() {
        // Connect to your SettleMint IPFS node
        auth := base64.StdEncoding.EncodeToString([]byte("your-ipfs-id:your-password"))
        sh := shell.NewShell("https://your-ipfs-name.gke-region.settlemint.com/api/v0")
        sh.SetHeader("Authorization", "Basic "+auth)
        
        // Upload file example
        cid, err := sh.Add(os.Stdin)
        if err != nil {
            fmt.Fprintf(os.Stderr, "error: %s", err)
            os.Exit(1)
        }
        fmt.Printf("added %s\n", cid)
        
        // Retrieve file example
        data, err := sh.Cat(cid)
        if err != nil {
            fmt.Fprintf(os.Stderr, "error: %s", err)
            os.Exit(1)
        }
        
        // Process data stream
        // ...
    }
    ```
  </Tab>

  <Tab value="Java">
    ### Java Integration

    #### java-ipfs-http-client
    Java implementation for the IPFS HTTP API:

    ```groovy
    dependencies {
        implementation 'com.github.ipfs:java-ipfs-http-client:1.3.3'
    }
    ```

    ```java
    import io.ipfs.api.IPFS;
    import io.ipfs.api.MerkleNode;
    import io.ipfs.api.NamedStreamable;

    import java.io.File;
    import java.io.IOException;
    import java.util.Base64;
    import java.util.HashMap;
    import java.util.Map;

    public class IPFSExample {
        public static void main(String[] args) throws IOException {
            // Connect to your SettleMint IPFS node
            String auth = Base64.getEncoder().encodeToString("your-ipfs-id:your-password".getBytes());
            
            IPFS ipfs = new IPFS("your-ipfs-name.gke-region.settlemint.com", 443, "/api/v0", "https");
            Map<String, String> headers = new HashMap<>();
            headers.put("Authorization", "Basic " + auth);
            ipfs.setRequestHeaders(headers);
            
            // Upload file example
            NamedStreamable.FileWrapper file = new NamedStreamable.FileWrapper(new File("path/to/file"));
            MerkleNode added = ipfs.add(file).get(0);
            String cid = added.hash.toString();
            
            // Retrieve file example
            byte[] fileContents = ipfs.cat(cid);
        }
    }
    ```
  </Tab>

  <Tab value="CLI">
    ### IPFS CLI Commands

    The IPFS CLI provides powerful command-line access to all IPFS functionality. Here are essential commands for managing your SettleMint IPFS instance:

    #### Installation & Configuration

    ```bash
    # Install IPFS CLI
    curl -O https://dist.ipfs.tech/kubo/v0.24.0/kubo_v0.24.0_linux-amd64.tar.gz
    tar -xvzf kubo_v0.24.0_linux-amd64.tar.gz
    cd kubo && sudo bash install.sh

    # Configure to use SettleMint IPFS endpoint
    export IPFS_API="https://your-ipfs-name.gke-region.settlemint.com/api/v0"
    export IPFS_AUTH="Basic $(echo -n 'your-ipfs-id:your-password' | base64)"
    ```

    #### File Operations

    ```bash
    # Add files
    ipfs add file.txt                          # Add single file
    ipfs add -r folder/                        # Add directory recursively
    ipfs add --pin=false file.txt              # Add without pinning
    ipfs add --chunker=size-262144 large.file  # Custom chunk size
    ipfs add --hash=sha3-256 file.txt          # Use different hash algorithm

    # Retrieve files
    ipfs cat QmXxx...                          # Display file content
    ipfs get QmXxx...                          # Download file
    ipfs get -o output.txt QmXxx...            # Save to specific filename
    ipfs ls QmXxx...                           # List directory contents
    ```

    #### Pin Management

    ```bash
    # Pinning operations
    ipfs pin add QmXxx...                      # Pin content
    ipfs pin rm QmXxx...                       # Unpin content
    ipfs pin ls                                # List all pins
    ipfs pin ls --type=recursive               # List recursive pins
    ipfs pin ls --type=direct                  # List direct pins
    ipfs pin verify                            # Verify all pinned content

    # Remote pinning
    ipfs pin remote service add mysvc https://pinning-service.com key1234
    ipfs pin remote add --service=mysvc --name="Important File" QmXxx...
    ipfs pin remote ls --service=mysvc
    ```

    #### Advanced Operations

    ```bash
    # IPNS publishing
    ipfs name publish QmXxx...                 # Publish to IPNS
    ipfs name publish --key=mykey QmXxx...     # Use specific key
    ipfs name resolve <peer-id>                # Resolve IPNS name

    # DAG operations
    ipfs dag get QmXxx...                      # Get DAG node
    ipfs dag put object.json                   # Create DAG node
    ipfs dag stat QmXxx...                     # Get DAG statistics

    # Repository management
    ipfs repo stat                             # Show repo statistics
    ipfs repo gc                               # Garbage collect unpinned blocks
    ipfs repo verify                           # Verify repo integrity

    # Network diagnostics
    ipfs swarm peers                           # List connected peers
    ipfs swarm connect /p2p/peer-id            # Connect to specific peer
    ipfs dht findprovs QmXxx...                # Find content providers
    ipfs stats bw                              # Show bandwidth usage
    ```

    #### Batch Operations Script

    ```bash
    #!/bin/bash
    # Batch upload with pinning
    
    for file in *.jpg; do
      CID=$(ipfs add -q "$file")
      echo "Uploaded $file: $CID"
      ipfs pin add "$CID"
      echo "$file,$CID" >> uploaded_files.csv
    done
    ```

    #### CLI Best Practices

    <Callout type="warning">
      **Important CLI Tips:**
      - Always verify CIDs after upload using `ipfs pin ls`
      - Use `--progress` flag for large file uploads
      - Set appropriate chunk sizes for your use case
      - Regularly run `ipfs repo gc` to clean up space
      - Use `ipfs add --only-hash` to preview CID without uploading
    </Callout>
  </Tab>
</Tabs>

## Best Practices for Decentralized Storage

### Content Organization

<Card>
  <h4>Directory Structure Best Practices</h4>
  
  ```
  /project-name/
    ├── contracts/          # Smart contract related files
    │   ├── metadata/       # Contract metadata
    │   └── verification/   # Verification documents
    ├── nfts/              # NFT assets
    │   ├── images/        # Visual assets
    │   ├── metadata/      # NFT metadata files
    │   └── attributes/    # Trait definitions
    ├── documents/         # Legal/compliance docs
    │   ├── encrypted/     # Encrypted sensitive files
    │   └── public/        # Public documents
    └── backups/          # Data backups
        └── snapshots/     # State snapshots
  ```
</Card>

### Security Best Practices

#### 1. **Encryption for Sensitive Data**

```javascript
import { createCipher, createDecipher } from 'crypto';

// Encrypt before uploading to IPFS
class SecureIPFS {
  constructor(ipfs, encryptionKey) {
    this.ipfs = ipfs;
    this.encryptionKey = encryptionKey;
  }
  
  async addEncrypted(content, filename) {
    // Encrypt content
    const cipher = createCipher('aes-256-cbc', this.encryptionKey);
    let encrypted = cipher.update(content, 'utf8', 'hex');
    encrypted += cipher.final('hex');
    
    // Add metadata about encryption
    const metadata = {
      filename,
      encrypted: true,
      algorithm: 'aes-256-cbc',
      timestamp: Date.now()
    };
    
    // Upload encrypted content
    const result = await this.ipfs.add({
      content: encrypted,
      metadata
    });
    
    return {
      cid: result.cid,
      encrypted: true,
      metadata
    };
  }
  
  async getDecrypted(cid) {
    const encrypted = await this.ipfs.cat(cid);
    
    // Decrypt content
    const decipher = createDecipher('aes-256-cbc', this.encryptionKey);
    let decrypted = decipher.update(encrypted, 'hex', 'utf8');
    decrypted += decipher.final('utf8');
    
    return decrypted;
  }
}
```

#### 2. **Access Control Implementation**

```javascript
// Implement role-based access control
class IPFSAccessControl {
  constructor(ipfs, accessControlContract) {
    this.ipfs = ipfs;
    this.contract = accessControlContract;
  }
  
  async addWithAccess(content, allowedAddresses) {
    // Upload content
    const result = await this.ipfs.add(content);
    
    // Register access permissions on-chain
    await this.contract.setAccess(
      result.cid,
      allowedAddresses,
      { gasLimit: 200000 }
    );
    
    return result.cid;
  }
  
  async getWithPermission(cid, userAddress) {
    // Check on-chain permissions
    const hasAccess = await this.contract.hasAccess(cid, userAddress);
    
    if (!hasAccess) {
      throw new Error('Access denied');
    }
    
    return this.ipfs.cat(cid);
  }
}
```

### Performance Optimization

#### 1. **Chunking Strategy**

```javascript
// Optimal chunking for different file types
const chunkingStrategy = {
  // Small files (< 1MB): Single chunk
  small: { chunker: 'size-262144' },  // 256KB chunks
  
  // Medium files (1MB - 100MB): Balanced chunking
  medium: { chunker: 'rabin-avg-262144' },  // Rabin chunking
  
  // Large files (> 100MB): Aggressive chunking
  large: { 
    chunker: 'size-1048576',  // 1MB chunks
    rawLeaves: true,
    cidVersion: 1
  }
};

// Auto-select strategy based on file size
function getChunkingOptions(fileSize) {
  if (fileSize < 1024 * 1024) return chunkingStrategy.small;
  if (fileSize < 100 * 1024 * 1024) return chunkingStrategy.medium;
  return chunkingStrategy.large;
}
```

#### 2. **Caching Strategy**

```javascript
// Implement intelligent caching
class IPFSCache {
  constructor(ipfs, cacheSize = 100 * 1024 * 1024) {  // 100MB cache
    this.ipfs = ipfs;
    this.cache = new Map();
    this.cacheSize = cacheSize;
    this.currentSize = 0;
  }
  
  async get(cid) {
    // Check cache first
    if (this.cache.has(cid)) {
      const entry = this.cache.get(cid);
      entry.lastAccessed = Date.now();
      return entry.content;
    }
    
    // Fetch from IPFS
    const content = await this.ipfs.cat(cid);
    
    // Add to cache with LRU eviction
    this.addToCache(cid, content);
    
    return content;
  }
  
  addToCache(cid, content) {
    const size = content.length;
    
    // Evict old entries if needed
    while (this.currentSize + size > this.cacheSize && this.cache.size > 0) {
      const oldestKey = this.findOldestEntry();
      const oldestEntry = this.cache.get(oldestKey);
      this.currentSize -= oldestEntry.content.length;
      this.cache.delete(oldestKey);
    }
    
    // Add new entry
    this.cache.set(cid, {
      content,
      lastAccessed: Date.now()
    });
    this.currentSize += size;
  }
  
  findOldestEntry() {
    let oldestKey = null;
    let oldestTime = Infinity;
    
    for (const [key, entry] of this.cache.entries()) {
      if (entry.lastAccessed < oldestTime) {
        oldestTime = entry.lastAccessed;
        oldestKey = key;
      }
    }
    
    return oldestKey;
  }
}
```

### Data Persistence Strategy

#### 1. **Multi-Provider Pinning**

```javascript
// Ensure data persistence across multiple providers
class MultiProviderPinning {
  constructor(providers) {
    this.providers = providers;  // Array of IPFS providers
  }
  
  async pinAcrossProviders(cid, metadata) {
    const results = await Promise.allSettled(
      this.providers.map(provider => 
        this.pinToProvider(provider, cid, metadata)
      )
    );
    
    const successful = results.filter(r => r.status === 'fulfilled');
    const failed = results.filter(r => r.status === 'rejected');
    
    if (successful.length === 0) {
      throw new Error('Failed to pin to any provider');
    }
    
    return {
      cid,
      pinned: successful.length,
      failed: failed.length,
      providers: successful.map(r => r.value.provider)
    };
  }
  
  async pinToProvider(provider, cid, metadata) {
    try {
      const result = await provider.pin.add(cid, metadata);
      return { provider: provider.name, result };
    } catch (error) {
      console.error(`Failed to pin to ${provider.name}:`, error);
      throw error;
    }
  }
  
  // Verify pin health across providers
  async verifyPinHealth(cid) {
    const healthChecks = await Promise.allSettled(
      this.providers.map(async provider => ({
        provider: provider.name,
        healthy: await provider.pin.isPinned(cid)
      }))
    );
    
    return healthChecks
      .filter(r => r.status === 'fulfilled')
      .map(r => r.value);
  }
}
```

#### 2. **Automated Backup Strategy**

```javascript
// Implement automated backups
class IPFSBackupManager {
  constructor(ipfs, backupSchedule = '0 0 * * *') {  // Daily at midnight
    this.ipfs = ipfs;
    this.schedule = backupSchedule;
  }
  
  async createBackup(dataSelector) {
    const timestamp = new Date().toISOString();
    const backupData = await this.collectData(dataSelector);
    
    // Create backup manifest
    const manifest = {
      timestamp,
      version: '1.0',
      items: []
    };
    
    // Add all data to backup
    for (const item of backupData) {
      const result = await this.ipfs.add(item.content);
      manifest.items.push({
        name: item.name,
        cid: result.cid,
        size: item.content.length,
        type: item.type
      });
    }
    
    // Store manifest
    const manifestResult = await this.ipfs.add(
      JSON.stringify(manifest, null, 2)
    );
    
    // Pin everything
    await this.pinBackup(manifestResult.cid, manifest);
    
    return {
      backupCid: manifestResult.cid,
      timestamp,
      itemCount: manifest.items.length
    };
  }
  
  async restoreBackup(backupCid) {
    // Retrieve manifest
    const manifestData = await this.ipfs.cat(backupCid);
    const manifest = JSON.parse(manifestData);
    
    // Restore all items
    const restored = [];
    for (const item of manifest.items) {
      const content = await this.ipfs.cat(item.cid);
      restored.push({
        name: item.name,
        content,
        cid: item.cid
      });
    }
    
    return {
      timestamp: manifest.timestamp,
      items: restored
    };
  }
}
```

### Monitoring and Analytics

```javascript
// IPFS usage monitoring
class IPFSMonitor {
  constructor(ipfs) {
    this.ipfs = ipfs;
    this.metrics = {
      uploads: [],
      downloads: [],
      pins: [],
      errors: []
    };
  }
  
  async trackOperation(type, operation) {
    const startTime = Date.now();
    
    try {
      const result = await operation();
      
      this.metrics[type].push({
        timestamp: new Date(),
        duration: Date.now() - startTime,
        success: true,
        size: result.size || 0
      });
      
      return result;
    } catch (error) {
      this.metrics.errors.push({
        timestamp: new Date(),
        type,
        error: error.message
      });
      
      throw error;
    }
  }
  
  getAnalytics() {
    return {
      totalUploads: this.metrics.uploads.length,
      totalDownloads: this.metrics.downloads.length,
      totalPins: this.metrics.pins.length,
      errorRate: this.metrics.errors.length / 
        (this.metrics.uploads.length + this.metrics.downloads.length),
      averageUploadTime: this.calculateAverage(this.metrics.uploads, 'duration'),
      averageDownloadTime: this.calculateAverage(this.metrics.downloads, 'duration'),
      totalDataTransferred: this.calculateTotal([...this.metrics.uploads, ...this.metrics.downloads], 'size')
    };
  }
  
  calculateAverage(items, field) {
    if (items.length === 0) return 0;
    return items.reduce((sum, item) => sum + item[field], 0) / items.length;
  }
  
  calculateTotal(items, field) {
    return items.reduce((sum, item) => sum + (item[field] || 0), 0);
  }
}
```

<Callout type="warning">
  **Critical Considerations:**
  - Always pin important files across multiple nodes
  - Implement proper access control for sensitive data
  - Monitor storage usage and implement cleanup policies
  - Use IPNS for mutable references when needed
  - Test disaster recovery procedures regularly
  - Keep encryption keys secure and separate from IPFS
</Callout>

---

## Troubleshooting

- **File Not Found?** – Ensure the file is **pinned** and accessible through an
  active IPFS node.
- **Slow Retrieval?** – Use **SettleMint's dedicated IPFS gateway** or public
  **IPFS gateways** for faster access.
- **Storage Limitations?** – Consider using **external pinning services** to
  maintain long-term file availability.

For further assistance, refer to **SettleMint's documentation** or the
**official IPFS documentation**.

---

## Additional resources

- **[IPFS Official Documentation](https://docs.ipfs.io/)**
- **[SettleMint Platform Guide](https://console.settlemint.com/documentation)**
- **[IPFS GitHub Repository](https://github.com/ipfs/ipfs)**
- **[IPFS & Blockchain Use Cases](https://ipfs.io/#use-cases)**

---

IPFS provides a **scalable, decentralized, and efficient** storage solution for
blockchain applications. Within **SettleMint**, IPFS can be easily used as a
**storage option**, allowing users to **store, retrieve, and reference files**
with minimal setup. By integrating IPFS into blockchain workflows, developers
can ensure **secure, tamper-proof, and cost-efficient off-chain storage**, while
keeping essential references **on-chain**.
